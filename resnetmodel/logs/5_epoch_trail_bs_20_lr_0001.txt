Batch 60: Loss = 1.8056
Batch 120: Loss = 2.0977
Batch 180: Loss = 1.7997
Batch 240: Loss = 1.7087
Batch 300: Loss = 1.6217
Batch 360: Loss = 1.9710
Batch 420: Loss = 2.0206
Batch 480: Loss = 2.0764
Batch 540: Loss = 2.1607
Batch 600: Loss = 1.6640
Batch 660: Loss = 1.5909
Batch 720: Loss = 1.3208
Batch 780: Loss = 2.5268
Batch 840: Loss = 1.5386
Batch 900: Loss = 1.6482
Batch 960: Loss = 1.7658
Batch 1020: Loss = 1.7659
Batch 1080: Loss = 2.1486
Batch 1140: Loss = 1.7515
Batch 1200: Loss = 1.5361
Batch 1260: Loss = 1.7780
Batch 1320: Loss = 2.0902
Batch 1380: Loss = 1.5508
Batch 1440: Loss = 1.6111
Batch 1500: Loss = 1.4598
Batch 1560: Loss = 1.9385
Batch 1620: Loss = 1.6070
Batch 1680: Loss = 1.7043
Batch 1740: Loss = 1.5222
Batch 1800: Loss = 1.6921
Batch 1860: Loss = 1.5958
Batch 1920: Loss = 1.6879
Batch 1980: Loss = 1.4940
Batch 2040: Loss = 1.6723
Batch 2100: Loss = 1.4558
Batch 2160: Loss = 1.3828
Batch 2220: Loss = 1.3518
Batch 2280: Loss = 1.9867
Batch 2340: Loss = 1.6502
Batch 2400: Loss = 1.7180
Batch 2460: Loss = 1.6064
Batch 2520: Loss = 1.7465
Batch 2580: Loss = 1.8801
Batch 2640: Loss = 1.2831
Batch 2700: Loss = 1.3586
Batch 2760: Loss = 1.3070
Batch 2820: Loss = 1.5092
Batch 2880: Loss = 1.6981
Batch 2940: Loss = 1.4272
Batch 3000: Loss = 1.2879
Batch 3060: Loss = 1.6116
Batch 3120: Loss = 1.3039
Batch 3180: Loss = 1.4352
Batch 3240: Loss = 1.3551
Batch 3300: Loss = 1.4117
Batch 3360: Loss = 1.4548
Batch 3420: Loss = 1.6549
Batch 3480: Loss = 1.4645
Batch 3540: Loss = 1.4968
Batch 3600: Loss = 1.5525
Batch 3660: Loss = 1.8029
Batch 3720: Loss = 1.4071
Batch 3780: Loss = 1.3634
Batch 3840: Loss = 1.2032
Batch 3900: Loss = 1.5148
Batch 3960: Loss = 1.2316
Batch 4020: Loss = 1.1916
Batch 4080: Loss = 1.1122
Batch 4140: Loss = 1.5452
Batch 4200: Loss = 1.3094
Batch 4260: Loss = 1.4150
Batch 4320: Loss = 1.4311
Batch 4380: Loss = 1.3913
Batch 4440: Loss = 1.0943
Batch 4500: Loss = 1.1873
Epoch [1/5] Train Loss: 1.6470 | Train Acc: 40.05% Val Loss: 1.4741 | Val Acc: 46.62%
Batch 60: Loss = 1.4562
Batch 120: Loss = 1.1627
Batch 180: Loss = 1.3227
Batch 240: Loss = 1.3792
Batch 300: Loss = 1.3357
Batch 360: Loss = 0.9987
Batch 420: Loss = 1.7592
Batch 480: Loss = 1.1216
Batch 540: Loss = 1.5160
Batch 600: Loss = 1.8904
Batch 660: Loss = 1.3029
Batch 720: Loss = 1.3479
Batch 780: Loss = 1.1990
Batch 840: Loss = 1.5904
Batch 900: Loss = 1.3239
Batch 960: Loss = 1.1658
Batch 1020: Loss = 1.1452
Batch 1080: Loss = 1.4022
Batch 1140: Loss = 1.2764
Batch 1200: Loss = 1.2794
Batch 1260: Loss = 1.3651
Batch 1320: Loss = 1.6694
Batch 1380: Loss = 1.0372
Batch 1440: Loss = 1.3525
Batch 1500: Loss = 1.1647
Batch 1560: Loss = 1.5549
Batch 1620: Loss = 1.1648
Batch 1680: Loss = 1.3946
Batch 1740: Loss = 1.1953
Batch 1800: Loss = 1.1331
Batch 1860: Loss = 1.2397
Batch 1920: Loss = 1.0646
Batch 1980: Loss = 1.1434
Batch 2040: Loss = 1.5722
Batch 2100: Loss = 1.4316
Batch 2160: Loss = 1.8441
Batch 2220: Loss = 1.0211
Batch 2280: Loss = 0.7578
Batch 2340: Loss = 1.0924
Batch 2400: Loss = 1.4610
Batch 2460: Loss = 1.4309
Batch 2520: Loss = 1.4016
Batch 2580: Loss = 1.1218
Batch 2640: Loss = 1.1475
Batch 2700: Loss = 1.0268
Batch 2760: Loss = 1.1658
Batch 2820: Loss = 1.1490
Batch 2880: Loss = 1.1475
Batch 2940: Loss = 1.2704
Batch 3000: Loss = 1.4637
Batch 3060: Loss = 0.7195
Batch 3120: Loss = 0.9074
Batch 3180: Loss = 1.3146
Batch 3240: Loss = 1.5190
Batch 3300: Loss = 1.5601
Batch 3360: Loss = 1.1098
Batch 3420: Loss = 0.9894
Batch 3480: Loss = 1.4408
Batch 3540: Loss = 1.4965
Batch 3600: Loss = 1.7488
Batch 3660: Loss = 0.9275
Batch 3720: Loss = 1.3120
Batch 3780: Loss = 1.5273
Batch 3840: Loss = 1.5001
Batch 3900: Loss = 1.1102
Batch 3960: Loss = 1.1005
Batch 4020: Loss = 1.0928
Batch 4080: Loss = 1.3002
Batch 4140: Loss = 1.0367
Batch 4200: Loss = 1.3544
Batch 4260: Loss = 1.4154
Batch 4320: Loss = 1.0925
Batch 4380: Loss = 1.3712
Batch 4440: Loss = 1.2961
Batch 4500: Loss = 0.7120
Epoch [2/5] Train Loss: 1.3487 | Train Acc: 51.29% Val Loss: 1.4407 | Val Acc: 48.93%
Batch 60: Loss = 1.0256
Batch 120: Loss = 0.9440
Batch 180: Loss = 1.0384
Batch 240: Loss = 1.0647
Batch 300: Loss = 1.7422
Batch 360: Loss = 1.3135
Batch 420: Loss = 1.8359
Batch 480: Loss = 1.4736
Batch 540: Loss = 1.3508
Batch 600: Loss = 0.9627
Batch 660: Loss = 1.0827
Batch 720: Loss = 1.1862
Batch 780: Loss = 1.5023
Batch 840: Loss = 1.1919
Batch 900: Loss = 1.5194
Batch 960: Loss = 1.1423
Batch 1020: Loss = 1.2172
Batch 1080: Loss = 1.4972
Batch 1140: Loss = 1.0689
Batch 1200: Loss = 1.2947
Batch 1260: Loss = 0.9711
Batch 1320: Loss = 1.1435
Batch 1380: Loss = 1.3848
Batch 1440: Loss = 1.3523
Batch 1500: Loss = 0.9489
Batch 1560: Loss = 1.0713
Batch 1620: Loss = 1.5111
Batch 1680: Loss = 1.0455
Batch 1740: Loss = 1.3246
Batch 1800: Loss = 0.8463
Batch 1860: Loss = 1.0608
Batch 1920: Loss = 1.6666
Batch 1980: Loss = 1.2668
Batch 2040: Loss = 1.1155
Batch 2100: Loss = 0.8339
Batch 2160: Loss = 1.3568
Batch 2220: Loss = 1.6953
Batch 2280: Loss = 1.4624
Batch 2340: Loss = 1.4906
Batch 2400: Loss = 1.5785
Batch 2460: Loss = 1.7660
Batch 2520: Loss = 1.2345
Batch 2580: Loss = 1.3228
Batch 2640: Loss = 1.1285
Batch 2700: Loss = 1.2540
Batch 2760: Loss = 1.4450
Batch 2820: Loss = 1.3789
Batch 2880: Loss = 1.0459
Batch 2940: Loss = 1.4419
Batch 3000: Loss = 1.3737
Batch 3060: Loss = 0.9154
Batch 3120: Loss = 0.9992
Batch 3180: Loss = 1.5674
Batch 3240: Loss = 1.3808
Batch 3300: Loss = 1.1241
Batch 3360: Loss = 1.0157
Batch 3420: Loss = 1.2998
Batch 3480: Loss = 1.0899
Batch 3540: Loss = 1.3265
Batch 3600: Loss = 0.9738
Batch 3660: Loss = 1.1851
Batch 3720: Loss = 1.0816
Batch 3780: Loss = 0.9699
Batch 3840: Loss = 0.7619
Batch 3900: Loss = 1.3923
Batch 3960: Loss = 0.8552
Batch 4020: Loss = 1.4864
Batch 4080: Loss = 0.8445
Batch 4140: Loss = 1.1744
Batch 4200: Loss = 1.1661
Batch 4260: Loss = 1.1237
Batch 4320: Loss = 0.9325
Batch 4380: Loss = 1.0702
Batch 4440: Loss = 1.3769
Batch 4500: Loss = 1.4187
Epoch [3/5] Train Loss: 1.1931 | Train Acc: 57.37% Val Loss: 1.3032 | Val Acc: 54.21%
Batch 60: Loss = 0.9822
Batch 120: Loss = 1.0721
Batch 180: Loss = 1.6073
Batch 240: Loss = 1.2009
Batch 300: Loss = 1.4290
Batch 360: Loss = 1.2307
Batch 420: Loss = 0.6277
Batch 480: Loss = 1.4832
Batch 540: Loss = 0.9182
Batch 600: Loss = 0.8820
Batch 660: Loss = 1.4712
Batch 720: Loss = 0.6835
Batch 780: Loss = 1.3605
Batch 840: Loss = 1.0311
Batch 900: Loss = 0.8635
Batch 960: Loss = 1.1589
Batch 1020: Loss = 1.2397
Batch 1080: Loss = 1.5118
Batch 1140: Loss = 1.4831
Batch 1200: Loss = 1.4870
Batch 1260: Loss = 0.8505
Batch 1320: Loss = 0.9761
Batch 1380: Loss = 1.1897
Batch 1440: Loss = 1.4723
Batch 1500: Loss = 0.9596
Batch 1560: Loss = 0.9359
Batch 1620: Loss = 0.9720
Batch 1680: Loss = 0.8867
Batch 1740: Loss = 0.9464
Batch 1800: Loss = 1.3816
Batch 1860: Loss = 1.0847
Batch 1920: Loss = 0.9052
Batch 1980: Loss = 1.3958
Batch 2040: Loss = 1.1173
Batch 2100: Loss = 1.2338
Batch 2160: Loss = 1.1604
Batch 2220: Loss = 0.9510
Batch 2280: Loss = 1.3922
Batch 2340: Loss = 0.9572
Batch 2400: Loss = 1.3792
Batch 2460: Loss = 1.0677
Batch 2520: Loss = 0.9081
Batch 2580: Loss = 0.8596
Batch 2640: Loss = 0.8914
Batch 2700: Loss = 0.9807
Batch 2760: Loss = 1.0863
Batch 2820: Loss = 1.4500
Batch 2880: Loss = 1.0984
Batch 2940: Loss = 1.5208
Batch 3000: Loss = 1.4471
Batch 3060: Loss = 0.7505
Batch 3120: Loss = 1.2444
Batch 3180: Loss = 0.7118
Batch 3240: Loss = 0.6590
Batch 3300: Loss = 0.9834
Batch 3360: Loss = 0.9745
Batch 3420: Loss = 1.4453
Batch 3480: Loss = 1.1033
Batch 3540: Loss = 1.1144
Batch 3600: Loss = 0.5359
Batch 3660: Loss = 1.3640
Batch 3720: Loss = 0.9380
Batch 3780: Loss = 0.8199
Batch 3840: Loss = 0.6190
Batch 3900: Loss = 1.4428
Batch 3960: Loss = 0.9891
Batch 4020: Loss = 0.8548
Batch 4080: Loss = 0.8270
Batch 4140: Loss = 1.2356
Batch 4200: Loss = 0.6742
Batch 4260: Loss = 1.2113
Batch 4320: Loss = 1.7223
Batch 4380: Loss = 0.8266
Batch 4440: Loss = 0.9107
Batch 4500: Loss = 1.0940
Epoch [4/5] Train Loss: 1.0848 | Train Acc: 61.47% Val Loss: 1.1542 | Val Acc: 58.57%
Batch 60: Loss = 1.2382
Batch 120: Loss = 0.7543
Batch 180: Loss = 0.7758
Batch 240: Loss = 1.0219
Batch 300: Loss = 0.6843
Batch 360: Loss = 0.9356
Batch 420: Loss = 0.5979
Batch 480: Loss = 1.0419
Batch 540: Loss = 0.6898
Batch 600: Loss = 0.6866
Batch 660: Loss = 0.5680
Batch 720: Loss = 1.2181
Batch 780: Loss = 1.7612
Batch 840: Loss = 0.9034
Batch 900: Loss = 0.9563
Batch 960: Loss = 1.3825
Batch 1020: Loss = 1.3198
Batch 1080: Loss = 1.1272
Batch 1140: Loss = 0.9330
Batch 1200: Loss = 0.9068
Batch 1260: Loss = 1.4688
Batch 1320: Loss = 0.9536
Batch 1380: Loss = 0.7270
Batch 1440: Loss = 0.9903
Batch 1500: Loss = 1.0750
Batch 1560: Loss = 0.6054
Batch 1620: Loss = 0.6617
Batch 1680: Loss = 1.1201
Batch 1740: Loss = 0.8848
Batch 1800: Loss = 0.9191
Batch 1860: Loss = 0.7863
Batch 1920: Loss = 0.8451
Batch 1980: Loss = 1.0753
Batch 2040: Loss = 0.4282
Batch 2100: Loss = 0.9432
Batch 2160: Loss = 1.0495
Batch 2220: Loss = 0.9610
Batch 2280: Loss = 0.6962
Batch 2340: Loss = 1.2156
Batch 2400: Loss = 1.0260
Batch 2460: Loss = 0.8002
Batch 2520: Loss = 1.0005
Batch 2580: Loss = 1.4439
Batch 2640: Loss = 0.3942
Batch 2700: Loss = 0.7073
Batch 2760: Loss = 0.6593
Batch 2820: Loss = 0.8692
Batch 2880: Loss = 1.1103
Batch 2940: Loss = 1.0651
Batch 3000: Loss = 1.2538
Batch 3060: Loss = 1.3708
Batch 3120: Loss = 1.3601
Batch 3180: Loss = 1.3272
Batch 3240: Loss = 1.0021
Batch 3300: Loss = 0.9262
Batch 3360: Loss = 1.2014
Batch 3420: Loss = 0.9481
Batch 3480: Loss = 0.8860
Batch 3540: Loss = 1.4273
Batch 3600: Loss = 0.8782
Batch 3660: Loss = 0.9041
Batch 3720: Loss = 1.0130
Batch 3780: Loss = 1.1777
Batch 3840: Loss = 0.6088
Batch 3900: Loss = 0.8457
Batch 3960: Loss = 0.9544
Batch 4020: Loss = 0.7575
Batch 4080: Loss = 1.3521
Batch 4140: Loss = 1.0096
Batch 4200: Loss = 0.6971
Batch 4260: Loss = 1.2413
Batch 4320: Loss = 0.8529
Batch 4380: Loss = 1.2918
Batch 4440: Loss = 1.2541
Batch 4500: Loss = 0.8093
Epoch [5/5] Train Loss: 0.9861 | Train Acc: 64.96% Val Loss: 1.1053 | Val Acc: 60.64%

